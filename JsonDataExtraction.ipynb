{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text, Image and Table extraction from Json files \n",
    "\n",
    "\n",
    "Instructions: \n",
    "<br> <br>\n",
    "To run this code successfully, we will need to download the folders \"data\" and \"images\" respectively from the Onedrive on Teams. \n",
    "- Ensure that you keep this python notebook in your \"data\" folder. Also, \"images\" folder should be in the same directory as that of the \"data\" folder. \n",
    "- The first module returns all the images and tables with their respective captions which can be used to study the key-words\n",
    "- The second module will be used to extract images and table with respect to the keywords and then train our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the nested packages \n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2, json, os, re\n",
    "import glob, PyPDF2, shutil, textract\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "img_dir = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 1 :  Figures with Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-37986e1214fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mURLData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dsand\\appdata\\local\\programs\\python\\python37\\lib\\pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m                 \u001b[1;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data'"
     ]
    }
   ],
   "source": [
    "URLData = {}\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for i in range(len(json_data)):\n",
    "                res = [json_data[i]['renderURL'][6:], json_data[i]['caption']]\n",
    "                \n",
    "                URLData[res[0]] = res[1]\n",
    "                \n",
    "                '''\n",
    "                if res[0] in os.listdir(img_dir):\n",
    "                    img = Image.open(img_dir + '/' + res[0])\n",
    "                    plt.figure(dpi = 200)\n",
    "                    plt.title(res[1])\n",
    "                    plt.imshow(img, aspect='auto')\n",
    "                    plt.show()\n",
    "                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 2 : Image/Table selection by using keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1\n",
    "\n",
    "Any of these keywords ‘Bio-oil’, ‘oil’, ‘light fraction’, ‘heavy fraction’, ‘light oil’, ‘heavy oil’, ‘bio oil’, ‘biooil’, ‘bio-oils’, ‘biomass’, ‘biocrude’, ‘bio-crude’, ‘crude’, ‘product’ accompanied by ‘yield’, ‘carbon’, ‘recovery’, ‘CR’, ’production’, ‘distribution’, ‘product’.\n",
    "\n",
    "Pass case: IF (Keyword set A && Keyword set B) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "table_data = []\n",
    "\n",
    "keywordsA = [\"bio-oil\", \"oil\", \"lightfraction\", \"heavyfraction\", \"lightoil\", \"heavyoil\", \"biooil\",\n",
    "             \"biomass\", \"biocrude\", \"bio-crude\", \"product\"]\n",
    "keywordsB = [\"yeild\", \"yields\", \"carbon\", \"recovery\", \"CR\", \"production\", \"distribution\", \"product\"]\n",
    "\n",
    "# Make the keywords boundary-words\n",
    "patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n",
    "patternB = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsB]))\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for data in json_data:\n",
    "                if data['figType'] == \"Figure\":\n",
    "                    if bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n",
    "                        image_data.append(data['renderURL'][6:])\n",
    "                        \n",
    "                if data['figType'] == \"Table\":\n",
    "                    if bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n",
    "                        table_data.append(data['renderURL'][6:])\n",
    "                \n",
    "# Remove duplicates from the data\n",
    "image_data = set(image_data)\n",
    "table_data = set(table_data)\n",
    "\n",
    "# Copy all the images to Case1/images\n",
    "if not os.path.exists('Case1/images'):\n",
    "    os.makedirs('Case1/images')\n",
    "\n",
    "for image in image_data:\n",
    "    shutil.copyfile(img_dir + '/' + image, 'Case1/images' + '/' + image)\n",
    "    \n",
    "# Copy all the tables to Case1/tables\n",
    "if not os.path.exists('Case1/tables'):\n",
    "    os.makedirs('Case1/tables')\n",
    "    \n",
    "for table in table_data:\n",
    "    shutil.copyfile(img_dir + '/' + table, 'Case1/tables' + '/' + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2\n",
    "\n",
    "If the keywords ‘yield’, ‘carbon’, ‘recovery’, ‘CR’, ’production’, ‘product’ are present but other keywords such as ‘solid’, ‘gas’, ‘aqueous’, ‘glucose’, ‘gaseous’, ‘solids’ are absent and the word next to bio-oil is not ‘of’\n",
    "\n",
    "Pass case: IF ‘yield’, ‘carbon recovery’, ‘recoveries’ == True && ‘Keyword set A’ == False && wordn+1 == ‘of’ is false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "table_data = []\n",
    "\n",
    "keywordsA = [\"solid\", \"gas\", \"aqueous\", \"glucose\", \"gaseous\", \"solids\", \"bio-oil of\"]\n",
    "keywordsB = [\"yeild\", \"yields\", \"carbon\", \"recovery\", \"CR\", \"production\", \"distribution\", \"product\"]\n",
    "\n",
    "# Make the keywords boundary-words\n",
    "patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n",
    "patternB = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsB]))\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for data in json_data:\n",
    "                if data['figType'] == \"Figure\":\n",
    "                    if not bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n",
    "                        image_data.append(data['renderURL'][6:])\n",
    "                        \n",
    "                if data['figType'] == \"Table\":\n",
    "                    if not bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n",
    "                        table_data.append(data['renderURL'][6:])\n",
    "\n",
    "# Remove duplicates from the data\n",
    "image_data = set(image_data)\n",
    "table_data = set(table_data)\n",
    "\n",
    "# Create directory 'Case2/images' and copy the selected images\n",
    "if not os.path.exists('Case2/images'):\n",
    "    os.makedirs('Case2/images')\n",
    "\n",
    "for image in image_data:\n",
    "    shutil.copyfile(img_dir + '/' + image, 'Case2/images' + '/' + image)\n",
    "\n",
    "# Create directory 'Case2/tables' and copy the selected tables\n",
    "if not os.path.exists('Case2/tables'):\n",
    "    os.makedirs('Case2/tables')\n",
    "    \n",
    "for table in table_data:\n",
    "    shutil.copyfile(img_dir + '/' + table, 'Case2/tables' + '/' + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3\n",
    "\n",
    "Test for presence of ‘a)’,’b)’, ‘c)’ before checking for plot check\n",
    "\n",
    "Pass case: if ‘Keyword set A’ == true, don’t do plot check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "table_data = []\n",
    "total_images = []\n",
    "total_tables = []\n",
    "\n",
    "keywordsA = ['a\\)', 'b\\)', 'c\\)']\n",
    "\n",
    "# Make the keywords boundary-words\n",
    "patternA = re.compile('|'.join([word for word in keywordsA]))\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for data in json_data:\n",
    "                if data['figType'] == \"Figure\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        image_data.append(data['renderURL'][6:])\n",
    "                        \n",
    "                if data['figType'] == \"Table\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        table_data.append(data['renderURL'][6:])\n",
    "\n",
    "# Remove duplicates from the data\n",
    "image_data = set(image_data)\n",
    "table_data = set(table_data)\n",
    "\n",
    "# Create directory 'Case3/images' and copy the selected images\n",
    "if not os.path.exists('Case3/images'):\n",
    "    os.makedirs('Case3/images')\n",
    "\n",
    "for image in image_data:\n",
    "    shutil.copyfile(img_dir + '/' + image, 'Case3/images' + '/' + image)\n",
    "        \n",
    "# Create directory 'Case3/tables' and copy the selected tables\n",
    "if not os.path.exists('Case3/tables'):\n",
    "    os.makedirs('Case3/tables')\n",
    "\n",
    "for table in table_data:\n",
    "    shutil.copyfile(img_dir + '/' + table, 'Case3/tables' + '/' + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4\n",
    "\n",
    "‘GC/MS’, ‘‘GC-MS’, ‘GC MS’, ‘GCMS’, ‘ion chromatogram’, ‘gas chromatography’, ‘areas’, ‘chromatogram’, ‘peak’, ‘functional’, ’compounds’, ‘composition’ are present\n",
    "\n",
    "Pass case: IF Keyword set A == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "table_data = []\n",
    "\n",
    "keywordsA = [\"GC/MS\", \"GC-MS\", \"GC MS\", \"GCMS\", \"ion chromatogram\", \"gas chromatography\",\n",
    "             \"areas\", \"chromatogram\", \"peak\", \"functional\", \"compounds\", \"composition\"]\n",
    "\n",
    "# Make the keywords boundary-words\n",
    "patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for data in json_data:\n",
    "                if data['figType'] == \"Figure\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        image_data.append(data['renderURL'][6:])\n",
    "                        \n",
    "                if data['figType'] == \"Table\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        table_data.append(data['renderURL'][6:])\n",
    "\n",
    "# Remove duplicates from the data\n",
    "image_data = set(image_data)\n",
    "table_data = set(table_data)\n",
    "\n",
    "# Create directory 'Case4/images' and copy the selected images\n",
    "if not os.path.exists('Case4/images'):\n",
    "    os.makedirs('Case4/images')\n",
    "\n",
    "for image in image_data:\n",
    "    shutil.copyfile(img_dir + '/' + image, 'Case4/images' + '/' + image)\n",
    "        \n",
    "# Create directory 'Case4/tables' and copy the selected tables\n",
    "if not os.path.exists('Case4/tables'):\n",
    "    os.makedirs('Case4/tables')\n",
    "\n",
    "for table in table_data:\n",
    "    shutil.copyfile(img_dir + '/' + table, 'Case4/tables' + '/' + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5\n",
    "\n",
    "‘Biochemical’, ‘proximate’, ‘ultimate’, ‘elemental’ are present\n",
    "\n",
    "Pass case: IF Keyword set A == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "table_data = []\n",
    "\n",
    "keywordsA = [\"Biochemical\", \"proximate\", \"ultimate\", \"elemental\"]\n",
    "    \n",
    "# Make the keywords boundary-words\n",
    "patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n",
    "\n",
    "for path in Path(data_dir).iterdir():\n",
    "    if path.name.endswith('.json'):\n",
    "        with path.open(encoding = \"utf-8\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "                \n",
    "            for data in json_data:\n",
    "                if data['figType'] == \"Figure\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        image_data.append(data['renderURL'][6:])\n",
    "                        \n",
    "                if data['figType'] == \"Table\":\n",
    "                    if bool(patternA.findall(data['caption'])):\n",
    "                        table_data.append(data['renderURL'][6:])\n",
    "\n",
    "# Remove duplicates from the data\n",
    "image_data = set(image_data)\n",
    "table_data = set(table_data)\n",
    "\n",
    "# Create directory 'Case5/images' and copy the selected images\n",
    "if not os.path.exists('Case5/images'):\n",
    "    os.makedirs('Case5/images')\n",
    "\n",
    "for image in image_data:\n",
    "    shutil.copyfile(img_dir + '/' + image, 'Case5/images' + '/' + image)\n",
    "        \n",
    "# filtered is already created; so just create tables directory and copy all the selected tables\n",
    "if not os.path.exists('Case5/tables'):\n",
    "    os.makedirs('Case5/tables')\n",
    "\n",
    "for table in table_data:\n",
    "    shutil.copyfile(img_dir + '/' + table, 'Case5/tables' + '/' + table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in image_data:\n",
    "    if image in os.listdir(img_dir):\n",
    "        \n",
    "        img = cv2.imread(img_dir + '/' + image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edged = cv2.Canny(gray, 0, 250)\n",
    "        contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "        rects = sorted(rects, key=lambda x:x[2] * x[3], reverse=True)\n",
    "        x, y, w, h = rects[0]\n",
    "        \n",
    "        cv2.rectangle(img, (x,y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        plt.figure(dpi = 400)\n",
    "        plt.imshow(img, aspect='auto')\n",
    "        plt.show()\n",
    "\n",
    "        nrows, ncols = 1, 4\n",
    "        figsize = [16, 16]\n",
    "        kernelsize = [3, 5, 7, 9]\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "        for i, axi in enumerate(ax.flat):\n",
    "            crop_img = img[y:y + h, x:x + w].copy()\n",
    "            gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Median filter to remove noise\n",
    "            gray = cv2.medianBlur(gray, kernelsize[i])\n",
    "\n",
    "            edged = cv2.Canny(gray, 0, 250)\n",
    "\n",
    "            contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cv2.drawContours(crop_img, contours, -1, (0, 255, 0), 3)\n",
    "            axi.imshow(crop_img)\n",
    "\n",
    "            # get indices of row/column\n",
    "            rowid = i // ncols\n",
    "            colid = i % ncols\n",
    "\n",
    "            # write row/col indices as axes' title for identification\n",
    "            axi.set_title(\"Row:\" + str(rowid) + \", Col:\" + str(colid))\n",
    "\n",
    "        plt.tight_layout(True)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
